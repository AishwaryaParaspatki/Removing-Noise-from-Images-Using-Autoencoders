{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "195/195 [==============================] - 31s 159ms/step - loss: 0.7233\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 34s 172ms/step - loss: 0.6736\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 33s 169ms/step - loss: 0.6386\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 33s 167ms/step - loss: 0.5923\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 33s 167ms/step - loss: 0.5254\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 32s 165ms/step - loss: 0.4424\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 34s 174ms/step - loss: 0.3576\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 33s 168ms/step - loss: 0.2956\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 32s 167ms/step - loss: 0.2672\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 32s 166ms/step - loss: 0.2584\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Import noisy office documents dataset\n",
    "    noisy_imgs_path = 'Noisy_Documents/noisy/'\n",
    "    clean_imgs_path = 'Noisy_Documents/clean/'\n",
    "\n",
    "    X_train_noisy = []\n",
    "    X_train_clean = []\n",
    "\n",
    "    for file in sorted(os.listdir(noisy_imgs_path)):\n",
    "        img = load_img(noisy_imgs_path+file, color_mode='grayscale', target_size=(420,540))\n",
    "        img = img_to_array(img).astype('float32')/255\n",
    "        X_train_noisy.append(img)\n",
    "\n",
    "    for file in sorted(os.listdir(clean_imgs_path)):\n",
    "        img = load_img(clean_imgs_path+file, color_mode='grayscale', target_size=(420,540))\n",
    "        img = img_to_array(img).astype('float32')/255\n",
    "        X_train_clean.append(img) \n",
    "\n",
    "    # convert to numpy array\n",
    "    X_train_noisy = np.array(X_train_noisy) \n",
    "    X_train_clean = np.array(X_train_clean)\n",
    "\n",
    "    # use the first 20 noisy images as testing images\n",
    "    X_test_noisy = X_train_noisy[0:20,]\n",
    "    X_train_noisy = X_train_noisy[21:,]\n",
    "\n",
    "    # use the first 20 clean images as testing images\n",
    "    X_test_clean = X_train_clean[0:20,]\n",
    "    X_train_clean = X_train_clean[21:,]\n",
    "\n",
    "    # Build and train model\n",
    "    basic_conv_autoencoder = Sequential()\n",
    "    basic_conv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same', input_shape=(420,540,1)))\n",
    "    basic_conv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    basic_conv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same'))\n",
    "    basic_conv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    basic_conv_autoencoder.fit(X_train_noisy, X_train_clean, epochs=10)\n",
    "\n",
    "    output = basic_conv_autoencoder.predict(X_test_noisy)\n",
    "\n",
    "    # Plot Output\n",
    "    fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3)\n",
    "\n",
    "    randomly_selected_imgs = random.sample(range(X_test_noisy.shape[0]),2)\n",
    "\n",
    "    for i, ax in enumerate([ax1, ax4]):\n",
    "        idx = randomly_selected_imgs[i]\n",
    "        ax.imshow(X_test_noisy[idx].reshape(420,540), cmap='gray')\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Noisy Images\")\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    for i, ax in enumerate([ax2, ax5]):\n",
    "        idx = randomly_selected_imgs[i]\n",
    "        ax.imshow(X_test_clean[idx].reshape(420,540), cmap='gray')\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Clean Images\")\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    for i, ax in enumerate([ax3, ax6]):\n",
    "        idx = randomly_selected_imgs[i]\n",
    "        ax.imshow(output[idx].reshape(420,540), cmap='gray')\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Output Denoised Images\")\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
